# -*- coding: utf-8 -*-
"""Emotion_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XMfAMC_K5EemWyfScqd3JUfTigwlIocd
"""

from keras.utils import to_categorical
from keras.preprocessing.image import load_img, img_to_array
from keras.models import Sequential
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D
import os
import pandas as pd
import numpy as np

Train_dir = 'train'
Test_dir = 'test'

def createdataframe(dir):
    image_paths = []
    labels = []
    for label in sorted(os.listdir(dir)):
        label_path = os.path.join(dir, label)
        if not os.path.isdir(label_path):
            continue  # skip files like .DS_Store
        for imagename in os.listdir(label_path):
            image_paths.append(os.path.join(label_path, imagename))
            labels.append(label)
        print(label, "completed")
    return image_paths, labels

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

!unzip train.zip

!unzip test.zip

Train_dir = 'train'
Test_dir = 'test'



train = pd.DataFrame()
train["image"], train["label"] = createdataframe(Train_dir)

print(train)

test = pd.DataFrame()
test["image"], test["label"] = createdataframe(Test_dir)

print(test)

from tqdm.notebook import tqdm

def extract_features(images):
    features = []
    for image in tqdm(images):
        img = load_img(image, color_mode='grayscale', target_size=(48, 48))
        img = np.array(img)
        features.append(img)
    features = np.array(features) ## neural networks (like Keras/TensorFlow) expect a single NumPy array
    features = features.reshape(len(features), 48,48,1)
    return features

train_features = extract_features(train['image'])

test_features = extract_features(test['image'])

x_train = train_features/255.0
x_test = test_features/255.0

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
le.fit(train['label'])

y_train = le.transform(train['label'])
y_test = le.transform(test['label'])

y_train = to_categorical(y_train, num_classes = 7)
y_test = to_categorical(y_test, num_classes = 7)

from tensorflow.keras.layers import BatchNormalization

model = Sequential()

# Convolutional layers
model.add(Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)))
model.add(BatchNormalization())
model.add(MaxPooling2D((2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(64, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2,2)))
model.add(Dropout(0.25))

model.add(Conv2D(128, (3,3), activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2,2)))
model.add(Dropout(0.25))

# Flatten + Fully connected
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(7, activation='softmax'))

model.summary()

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #update the weights smartly, following the loss landscape, to minimize the loss.

from tensorflow.keras.callbacks import EarlyStopping

earlystop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)

model.fit(x_train, y_train, batch_size=64, epochs=50, validation_data=(x_test, y_test), callbacks=[earlystop])

model.save('best_emotion_model.h5')

test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {test_acc:.4f}")

